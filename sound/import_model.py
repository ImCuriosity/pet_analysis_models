#%%
# import
import torch
import torch.nn as nn  # nn ëª¨ë“ˆ ì„í¬íŠ¸ ì¶”ê°€
from transformers import Wav2Vec2Processor, Wav2Vec2Config, Wav2Vec2Model # í•„ìš”í•œ ëª¨ë¸ ì„í¬íŠ¸
import os
from pydub import AudioSegment

#%%
# ClassificationHeadì˜ ì •ì˜ (ì´ì „ì— ì‚¬ìš©í–ˆë˜ ì½”ë“œ)
class ClassificationHead(nn.Module):
    def __init__(self, config, num_labels):
        super().__init__()
        self.dense = nn.Linear(config.hidden_size, config.hidden_size)
        self.dropout = nn.Dropout(config.final_dropout)
        self.out_proj = nn.Linear(config.hidden_size, num_labels)
    def forward(self, hidden_states):
        hidden_states=self.dropout(hidden_states)
        hidden_states=self.dense(hidden_states)
        hidden_states=torch.tanh(hidden_states)
        hidden_states=self.dropout(hidden_states)
        hidden_states=self.out_proj(hidden_states)
        return hidden_states

# Wav2Vec2ForMultiLabelClassificationì˜ ì •ì˜ (ì˜¤ë¥˜ ìˆ˜ì • ë° ë³€ìˆ˜ ì •ì˜ í¬í•¨)
# ì°¸ê³ : num_activeness_classesì™€ num_positive_classesê°€ configì— ì €ì¥ë˜ì–´ ìˆì–´ì•¼ ì•ˆì „í•©ë‹ˆë‹¤.
num_activeness_classes = 2 # ì €ì¥ ì‹œ ì‚¬ìš©í–ˆë˜ ê°’ìœ¼ë¡œ ìˆ˜ì • í•„ìš”
num_positive_classes = 2 # ì €ì¥ ì‹œ ì‚¬ìš©í–ˆë˜ ê°’ìœ¼ë¡œ ìˆ˜ì • í•„ìš”

class Wav2Vec2ForMultiLabelClassification(nn.Module):
    # ğŸ’¡ ì˜¤ë¥˜ ìˆ˜ì •: __init ëŒ€ì‹  __init__ ì‚¬ìš©
    def __init__(self, config): 
        super().__init__()
        self.wav2vec2=Wav2Vec2Model(config)
        self.activeness_head=ClassificationHead(config, num_activeness_classes)
        self.positive_head=ClassificationHead(config,num_positive_classes)
        # forward í•¨ìˆ˜ì—ì„œ ì‚¬ìš©í•˜ê¸° ìœ„í•´ í´ë˜ìŠ¤ ë³€ìˆ˜ë¡œ ì €ì¥
        self.num_activeness_classes = num_activeness_classes
        self.num_positive_classes = num_positive_classes

    def forward(self, input_values, attention_mask=None, 
                        activeness_labels=None, positive_labels=None):
        outputs=self.wav2vec2(input_values, attention_mask=attention_mask)
        hidden_states=outputs[0]
        pooled_output=hidden_states.mean(dim=1)
        activeness_logits=self.activeness_head(pooled_output)
        positive_logits=self.positive_head(pooled_output)
        loss=None
        if activeness_labels is not None and positive_labels is not None:
            loss_fct=nn.CrossEntropyLoss()
            # í´ë˜ìŠ¤ ë³€ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ ë¡œìŠ¤ ê³„ì‚°
            activeness_loss=loss_fct(activeness_logits.view(-1, self.num_activeness_classes),
                                     activeness_labels.view(-1))
            positive_loss=loss_fct(positive_logits.view(-1, self.num_positive_classes), 
                                    positive_labels.view(-1))
            loss=activeness_loss + positive_loss 
        return{
            'loss': loss,
            'activeness_logits': activeness_logits,
            'positive_logits': positive_logits
        }
    
#%%
# ì €ì¥ëœ ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°
saved_model_path = r'C:\workspace\final_proj\dog_sound\save_path'

try:
    # ëª¨ë¸ ì„¤ì • ë¡œë“œ
    config = Wav2Vec2Config.from_pretrained(saved_model_path)
    # ì €ì¥ëœ ëª¨ë¸ ê°€ì¤‘ì¹˜ë¥¼ ì‚¬ìš©í•˜ì—¬ ëª¨ë¸ ë¡œë“œ
    loaded_model = Wav2Vec2ForMultiLabelClassification(config)
    # ëª¨ë¸ ê°€ì¤‘ì¹˜ íŒŒì¼ ë¡œë“œ
    model_weights_path = os.path.join(saved_model_path, 'pytorch_model.bin')
    # ì˜¤ë¥˜ í•´ê²° ì‹œë„
    state_dict = torch.load(model_weights_path, map_location=torch.device('cpu'))
    loaded_model.load_state_dict(state_dict, strict=False)
    # í”„ë¡œì„¸ì„œ ë¡œë“œ
    loaded_processor = Wav2Vec2Processor.from_pretrained(saved_model_path)
    # ëª¨ë¸ì„ ì‚¬ìš© ê°€ëŠ¥í•œ ì¥ì¹˜(GPU or CPU)ë¡œ ì´ë™
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    loaded_model.to(device)
    loaded_model.eval()
    print(f"\nëª¨ë¸ê³¼ í”„ë¡œì„¸ì„œë¥¼ ì„±ê³µì ìœ¼ë¡œ ë¶ˆëŸ¬ì™”ìŠµë‹ˆë‹¤. ì¥ì¹˜: {device}")
except FileNotFoundError:
    print(f"ì˜¤ë¥˜: ì§€ì •ëœ ê²½ë¡œì—ì„œ ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê²½ë¡œë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”: {saved_model_path}")
except Exception as e:
    print(f"ëª¨ë¸ì„ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")

#%%
# ì˜ˆ: C:\Users\YourUser\Downloads\ffmpeg-6.0-full_build\bin\
FFMPEG_BIN_DIR = r'C:\workspace\final_proj\dog_sound\ffmpeg-8.0\bin' 

# FFmpeg ê²½ë¡œë¥¼ os.environì— ì¶”ê°€í•˜ì—¬ pydubê°€ ì°¾ì„ ìˆ˜ ìˆê²Œ í•¨
# (ë‹¨, ì´ ë°©ì‹ì€ pydub/AudioSegmentë¥¼ ì„í¬íŠ¸í•˜ê¸° ì „ì— ìˆ˜í–‰ë˜ì–´ì•¼ í•©ë‹ˆë‹¤.)
os.environ["PATH"] += os.pathsep + FFMPEG_BIN_DIR
# os.environ['FFMPEG_PATH'] = os.path.join(FFMPEG_BIN_DIR, 'ffmpeg.exe') 
# os.environ['FFPROBE_PATH'] = os.path.join(FFMPEG_BIN_DIR, 'ffprobe.exe')

# ***************************************************************
# 2. .mp3 to .wav ë³€í™˜ í•¨ìˆ˜ (ê¸°ì¡´ ì½”ë“œ)
# ***************************************************************
def mp3_to_wav(mp3_path, wav_path):
    """
    Converts an MP3 file to a WAV file.
    """
    try:
        # mp3 íŒŒì¼ ì—¬ë¶€ í™•ì¸
        if not os.path.exists(mp3_path):
            raise FileNotFoundError(f'mp3 íŒŒì¼ ì°¾ì„ ìˆ˜ ì—†ìŒ: {mp3_path}')
        
        # mp3íŒŒì¼ ë¡œë“œ (pydubê°€ FFmpegì„ í˜¸ì¶œí•¨)
        audio = AudioSegment.from_mp3(mp3_path)
        
        # wav íŒŒì¼ë¡œ ì¶”ì¶œ
        audio.export(wav_path, format='wav')
        
        print(f"ì„±ê³µì ìœ¼ë¡œ ë³€í™˜: '{mp3_path}' to '{wav_path}'" )
        
    except FileNotFoundError as e:
        print(f'ì—ëŸ¬: {e}')
    except Exception as e:
        # FFmpeg ê²½ë¡œ ì„¤ì •ì´ ì˜ëª»ë˜ì—ˆì„ ë•Œ ì´ ì—ëŸ¬ê°€ ë°œìƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
        print(f'ë³€í™˜ ì¤‘ ì—ëŸ¬ (FFmpeg ê²½ë¡œ ë¬¸ì œì¼ ìˆ˜ ìˆìŒ): {e}')


# ***************************************************************
# 3. ì‚¬ìš© ì˜ˆì‹œ
# ***************************************************************
# Raw string (r)ì„ ì‚¬ìš©í•˜ì—¬ ë°±ìŠ¬ë˜ì‹œ ë¬¸ì œë¥¼ ë°©ì§€í•©ë‹ˆë‹¤.
# input_mp3_path = r'C:\workspace\final_proj\dog_sound\puppy_0004.mp3' 
# output_wav_path = r'C:\workspace\final_proj\dog_sound\puppy_0004_1.wav'

# í•¨ìˆ˜ í˜¸ì¶œ
# if FFMPEG_BIN_DIR:
#     mp3_to_wav(input_mp3_path, output_wav_path)
# else:
#     print("ğŸš¨ FFMPEG_BIN_DIR ë³€ìˆ˜ë¥¼ ì‚¬ìš©ìì˜ FFmpeg ê²½ë¡œë¡œ ë¨¼ì € ìˆ˜ì •í•´ì•¼ í•©ë‹ˆë‹¤.")

#%%
# .mp3 to .wav ë³€í™˜
# def mp3_to_wav(mp3_path, wav_path):
#     """
#     Converts an MP3 file to a WAV file.

#     Args:
#     mp3_path(str): The path to the input mp3 file.
#     wav_path(str): The path to save the output wav file.
#     """
#     try:
#         # mp3 íŒŒì¼ ì—¬ë¶€ í™•ì¸
#         if not os.path.exists(mp3_path):
#             raise FileNotFoundError(f'mp3 íŒŒì¼ ì°¾ì„ ìˆ˜ ì—†ìŒ: {mp3_path}')
#         # mp3íŒŒì¼ ë¡œë“œ
#         audio = AudioSegment.from_mp3(mp3_path)
#         # wav íŒŒì¼ë¡œ ì¶”ì¶œ
#         audio.export(wav_path, format='wav')
#         print(f"ì„±ê³µì ìœ¼ë¡œ ë³€í™˜ '{mp3_path} to {wav_path}" )
#     except FileNotFoundError as e:
#         print(f'ì—ëŸ¬: {e}')
#     except Exception as e:
#         print(f'ë³€í™˜ ì¤‘ ì—ëŸ¬: {e}')

# ì‚¬ìš© ì˜ˆì‹œ
# input_mp3_path = '/content/drive/MyDrive/ITWILL(á„€á…µá„†á…¡á†¯á„‘á…³á†¯á„Œá…¦á†¨)/á„Œá…¥á†¼á„’á…§á†«/your_audio.mp3' # Replace with your actual MP3 path
# output_wav_path = '/content/drive/MyDrive/ITWILL(á„€á…µá„†á…¡á†¯á„‘á…³á†¯á„Œá…¦á†¨)/á„Œá…¥á†¼á„’á…§á†«/your_audio.wav' # Replace with your desired output WAV path

# Call the function with your paths
# mp3_to_wav(input_mp3_path, output_wav_path)

# %%
# í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ (ì´ì „ì— ì„í¬íŠ¸ë˜ì§€ ì•Šì€ ê²ƒë§Œ)
import torch
import torchaudio
import numpy as np
import os

# ì˜ˆì¸¡í•  ìƒˆë¡œìš´ MP3 íŒŒì¼ ê²½ë¡œ ì„¤ì • (ì—¬ê¸°ë¥¼ ìˆ˜ì •í•˜ì„¸ìš”!)
input_mp3_path = r'C:\workspace\final_proj\dog_sound\puppy_0004.mp3' # ì‹¤ì œ MP3 íŒŒì¼ ê²½ë¡œë¡œ ë³€ê²½í•´ì£¼ì„¸ìš”.
# ë³€í™˜ëœ WAV íŒŒì¼ì„ ì €ì¥í•  ê²½ë¡œ ì„¤ì •
output_wav_path = r'C:\workspace\final_proj\dog_sound\puppy_0004.wav' # ì›í•˜ëŠ” ì¶œë ¥ WAV íŒŒì¼ ê²½ë¡œë¡œ ë³€ê²½í•´ì£¼ì„¸ìš”.

# ì´ì „ì— ì •ì˜í•œ mp3_to_wav í•¨ìˆ˜ê°€ ìˆëŠ”ì§€ í™•ì¸
if 'mp3_to_wav' not in globals():
    print("mp3_to_wav í•¨ìˆ˜ê°€ ì •ì˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì´ì „ ë‹¨ê³„ë¥¼ ì‹¤í–‰í•˜ì—¬ í•¨ìˆ˜ë¥¼ ì •ì˜í•´ì£¼ì„¸ìš”.")
elif 'loaded_model' not in locals() or 'loaded_processor' not in locals():
    print("ë¶ˆëŸ¬ì˜¨ ëª¨ë¸(loaded_model) ë˜ëŠ” í”„ë¡œì„¸ì„œ(loaded_processor)ê°€ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì´ì „ ë‹¨ê³„ë¥¼ ì‹¤í–‰í•˜ì—¬ ëª¨ë¸ê³¼ í”„ë¡œì„¸ì„œë¥¼ ë¡œë“œí•´ì£¼ì„¸ìš”.")
else:
    try:
        # 1. MP3 íŒŒì¼ì„ WAV íŒŒì¼ë¡œ ë³€í™˜
        print(f"MP3 íŒŒì¼ì„ WAVë¡œ ë³€í™˜í•©ë‹ˆë‹¤: {input_mp3_path} -> {output_wav_path}")
        mp3_to_wav(input_mp3_path, output_wav_path)

        # ë³€í™˜ëœ WAV íŒŒì¼ì´ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
        if not os.path.exists(output_wav_path):
            print(f"ì˜¤ë¥˜: WAV íŒŒì¼ ë³€í™˜ì— ì‹¤íŒ¨í–ˆê±°ë‚˜ ë³€í™˜ëœ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {output_wav_path}")
        else:
            # 2. ë³€í™˜ëœ WAV íŒŒì¼ ë¡œë“œ ë° ì „ì²˜ë¦¬
            print(f"\në³€í™˜ëœ WAV íŒŒì¼ë¡œ ì˜ˆì¸¡ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤: {output_wav_path}")
            speech_array, sampling_rate = torchaudio.load(output_wav_path)

            # ëª¨ë¸ì˜ ìƒ˜í”Œë§ ì†ë„ (16000 Hz)ì™€ ë‹¤ë¥¼ ê²½ìš° ë¦¬ìƒ˜í”Œë§
            target_sampling_rate = 16000
            if sampling_rate != target_sampling_rate:
                resampler = torchaudio.transforms.Resample(orig_freq=sampling_rate, new_freq=target_sampling_rate)
                speech_array = resampler(speech_array)
                sampling_rate = target_sampling_rate

            # Wav2Vec2 ì…ë ¥ í˜•ì‹ì— ë§ê²Œ ë³€í™˜
            input_values = loaded_processor(speech_array.squeeze(0).numpy(), sampling_rate=sampling_rate, return_tensors="pt").input_values

            # 3. ë¶ˆëŸ¬ì˜¨ ëª¨ë¸ë¡œ ì˜ˆì¸¡
            loaded_model.eval()
            with torch.no_grad():
                # ğŸ’¡ ì˜¤ë¥˜ ìˆ˜ì •: loaded_model.device ëŒ€ì‹  ì •ì˜ëœ device ë³€ìˆ˜ ì‚¬ìš©
                input_values = input_values.to(device)
                outputs = loaded_model(input_values)

            # ë¡œì§“ ê°€ì ¸ì˜¤ê¸°
            activeness_logits = outputs["activeness_logits"]
            positive_logits = outputs["positive_logits"]

            # 4. ê²°ê³¼ í•´ì„
            activeness_probs = torch.softmax(activeness_logits, dim=-1)
            positive_probs = torch.softmax(positive_logits, dim=-1)

            activeness_pred_id = torch.argmax(activeness_probs, dim=-1).item()
            positive_pred_id = torch.argmax(positive_probs, dim=-1).item()

            # ë ˆì´ë¸” IDë¥¼ ì‹¤ì œ ë ˆì´ë¸” ë¬¸ìì—´ë¡œ ë³€í™˜
            # activeness_label_mapê³¼ positive_label_mapì€ ì´ì „ ë‹¨ê³„ì—ì„œ ì •ì˜ë˜ì—ˆì–´ì•¼ í•©ë‹ˆë‹¤.
            if 'activeness_label_map' not in locals() or 'positive_label_map' not in locals():
                 print("ê²½ê³ : activeness_label_map ë˜ëŠ” positive_label_mapì´ ì •ì˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë ˆì´ë¸” ë¬¸ìì—´ ë³€í™˜ì´ ì˜¬ë°”ë¥´ì§€ ì•Šì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
                 # ì„ì‹œë¡œ ê¸°ë³¸ ë§µ ì‚¬ìš© (ì´ì „ ì½”ë“œ ì…€ì—ì„œ ì‚¬ìš©ëœ ê°’)
                 activeness_label_map = {0: 'passive', 1: 'active'}
                 positive_label_map = {0: 'negative', 1: 'positive'}

            # ğŸ’¡ ì˜¤ë¥˜ ìˆ˜ì •: label_mapì˜ valueì—ì„œ keyë¥¼ ì°¾ëŠ” ëŒ€ì‹  keyì—ì„œ valueë¥¼ ì°¾ë„ë¡ ìˆ˜ì •
            # ë˜í•œ, activeness_pred_idì™€ positive_pred_idëŠ” ì´ë¯¸ 0 ë˜ëŠ” 1ì´ë¯€ë¡œ, ì´ë¥¼ ì§ì ‘ label_mapì˜ keyë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤.
            activeness_pred_label = activeness_label_map.get(activeness_pred_id, f"Unknown ID: {activeness_pred_id}")
            positive_pred_label = positive_label_map.get(positive_pred_id, f"Unknown ID: {positive_pred_id}")


            print(f"ì˜ˆì¸¡ëœ Activeness: {activeness_pred_label} (í™•ë¥ : {activeness_probs[0][activeness_pred_id].item():.4f})")
            print(f"ì˜ˆì¸¡ëœ Positive: {positive_pred_label} (í™•ë¥ : {positive_probs[0][positive_pred_id].item():.4f})")

    except FileNotFoundError as e:
        print(f"ì˜¤ë¥˜: íŒŒì¼ ê´€ë ¨ ì˜¤ë¥˜ ë°œìƒ - {e}")
    except Exception as e:
        print(f"ì˜¤ë””ì˜¤ ë³€í™˜ ë˜ëŠ” ì˜ˆì¸¡ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")

